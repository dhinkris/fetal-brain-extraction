{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cnmc/anaconda3/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, sys, shutil\n",
    "import scipy.ndimage as snd\n",
    "import h5py\n",
    "import SimpleITK as sitk\n",
    "from shutil import copy\n",
    "import nibabel as nib\n",
    "import skimage.morphology as morph\n",
    "from skimage.feature import canny\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "selem = morph.disk(2)\n",
    "def getWeightMap(label):\n",
    "    label = np.argmax(label, axis=3)[0]\n",
    "    edge = np.float32(morph.binary_dilation(canny(np.float32(label)), selem))\n",
    "    weight_map = np.zeros(label.shape)\n",
    "    weight_map[np.where(label>0)] = 7\n",
    "    weight_map = weight_map + 1\n",
    "    weight_map[np.where(edge==1.0)] = 25\n",
    "#     weight_map[np.where(label == 2.0)] = 15\n",
    "    return np.uint8(weight_map[None,:,:])\n",
    "\n",
    "def downSampleImage(image):\n",
    "    return np.float64(snd.interpolation.zoom(image, 0.5))\n",
    "\n",
    "def loadDicomVolume(file_path, itk_image):\n",
    "    reader = sitk.ImageSeriesReader()\n",
    "    reader.SetOutputPixelType(sitk.sitkFloat32)\n",
    "    dicom_names = reader.GetGDCMSeriesFileNames(file_path)\n",
    "    reader.SetFileNames(dicom_names)\n",
    "    itk_image = reader.Execute()\n",
    "    image_vol = sitk.GetArrayFromImage(self.itk_image)\n",
    "    image_vol = np.transpose(image_vol,(1,2,0))\n",
    "    return np.float32(image_vol)\n",
    "\n",
    "def histogram_equalization(arr):\n",
    "    nbr_bins = 256\n",
    "    imhist, bins = np.histogram(arr.flatten(), nbr_bins, normed = True)\n",
    "    cdf = imhist.cumsum()\n",
    "    cdf = 255 * cdf / cdf[-1]\n",
    "    original_shape = arr.shape\n",
    "    arr = np.interp(arr.flatten(), bins[:-1], cdf)\n",
    "    out_arr = arr.reshape(original_shape)\n",
    "    return out_arr\n",
    "\n",
    "def normalize(x):\n",
    "    x = np.float32(x)\n",
    "    min_val = np.min(x)\n",
    "    max_val = np.max(x)\n",
    "    ret_val = (x - min_val) / (max_val - min_val)\n",
    "    return ret_val\n",
    "\n",
    "def downSample1(slc):\n",
    "    return snd.interpolation.zoom(slc,0.5)\n",
    "\n",
    "def makeLablel(lbl, num_class = 3):\n",
    "    if num_class == 2:\n",
    "        lbl[lbl==2] = 1\n",
    "    \n",
    "    lbl = oneHot(lbl,num_class)\n",
    "    return np.uint8(lbl[None,:,:])\n",
    "\n",
    "def get_z_minmaxforbrain(lbl):\n",
    "    lbl[lbl==2] = 1\n",
    "    maxes = np.max(lbl,axis =(1,2))\n",
    "    nonzero_maxes = np.nonzero(maxes)[0]\n",
    "    mn, mx = nonzero_maxes[0] - 10, nonzero_maxes[-1] + 10\n",
    "    if mn < 0:\n",
    "        mn = 0\n",
    "    if mx >= lbl.shape[0]:\n",
    "        mx = lbl.shape[0]-1\n",
    "    return mn, mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(*args,**kwargs):\n",
    "    \"\"\" Handy function to show multiple plots in on row, possibly with different cmaps and titles\n",
    "    Usage: \n",
    "    imshow(img1, title=\"myPlot\")\n",
    "    imshow(img1,img2, title=['title1','title2'])\n",
    "    imshow(img1,img2, cmap='hot')\n",
    "    imshow(img1,img2,cmap=['gray','Blues']) \"\"\"\n",
    "    cmap = kwargs.get('cmap', 'gray')\n",
    "    title= kwargs.get('title','')\n",
    "    if len(args)==0:\n",
    "        raise ValueError(\"No images given to imshow\")\n",
    "    elif len(args)==1:\n",
    "        plt.title(title)\n",
    "        plt.imshow(args[0], interpolation='none')\n",
    "    else:\n",
    "        n=len(args)\n",
    "        if type(cmap)==str:\n",
    "            cmap = [cmap]*n\n",
    "        if type(title)==str:\n",
    "            title= [title]*n\n",
    "        plt.figure(figsize=(n*5,10))\n",
    "        for i in range(n):\n",
    "            plt.subplot(1,n,i+1)\n",
    "            plt.title(title[i])\n",
    "            plt.imshow(args[i], cmap[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./raw_data/Normal01/\n",
      "./raw_data/Normal02/\n",
      "13 13\n"
     ]
    }
   ],
   "source": [
    "root = './raw_data/'\n",
    "folders = ['Normal01/', 'Normal02/']\n",
    "dest = './processed_data/hdf5_file/'\n",
    "\n",
    "if not os.path.exists(dest):\n",
    "    os.makedirs(dest)\n",
    "vols, segs = [], []\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(root, folder)\n",
    "    print(folder_path)\n",
    "    for f in next(os.walk(folder_path))[2]:\n",
    "        vols.append(os.path.join(folder_path, f))\n",
    "    for s in next(os.walk(os.path.join(folder_path, \"ManualSegmentation\")))[2]:\n",
    "        segs.append(os.path.join(os.path.join(folder_path, \"ManualSegmentation\"), s))\n",
    "vols.sort()\n",
    "segs.sort()\n",
    "print len(vols), len(segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint16), 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cnmc/anaconda3/lib/python2.7/site-packages/ipykernel_launcher.py:13: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  del sys.path[0]\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-2e09db2ae64f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mslc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mslc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mlbl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmakeLablel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mweight_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetWeightMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlbl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-151-466f486e0445>\u001b[0m in \u001b[0;36mmakeLablel\u001b[0;34m(lbl, num_class)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mlbl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlbl\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlbl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mlbl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moneHot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlbl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlbl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "for vol_path in tqdm(vols):\n",
    "#     print(\"working on : \" + vol_path)\n",
    "    label_path = vol_path[:20] + \"ManualSegmentation/mask\"+vol_path.split(\"/\").pop()\n",
    "    vol_img = sitk.ReadImage(vol_path)\n",
    "    label = sitk.GetArrayFromImage(sitk.ReadImage(label_path))\n",
    "    vol = sitk.GetArrayFromImage(vol_img)\n",
    "    \n",
    "#     vol = histogram_equalization(vol1)\n",
    "    vol = normalize(vol)\n",
    "    \n",
    "    z_min, z_max = get_z_minmaxforbrain(label)\n",
    "    for i in range(z_min, z_max):\n",
    "        slc = np.expand_dims(vol[i,:,:],axis = 3)\n",
    "        slc = np.expand_dims(slc,axis = 0)\n",
    "        lbl = makeLablel(label[i,:,:],2)\n",
    "        weight_map = np.expand_dims(getWeightMap(lbl),axis=3)\n",
    "        \n",
    "#         print slc.shape, lbl.shape, weight_map.shape\n",
    "        if i == z_min + z_max//2: imshow(np.squeeze(slc), np.squeeze(lbl)[:,:,1])\n",
    "        hp = h5py.File(os.path.join(dest, vol_path.split(\"/\")[2]+\"_\"+vol_path.split(\"/\")[3]+'_slice_'+ str(i)+'.hdf5'),'w')\n",
    "        hp.create_dataset('image', data=slc)\n",
    "        hp.create_dataset('label', data=lbl)\n",
    "        hp.create_dataset('weight_map', data=weight_map)\n",
    "        hp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of samples: 0\n",
      "Training Set Done!!\n",
      "Validation Set Done!!\n",
      "Test Set Done!!\n",
      "Data Splitting Done...\n"
     ]
    }
   ],
   "source": [
    "def generate_train_validate_test_set(src_path, dest_path):\n",
    "    \"\"\"\n",
    "    Split the data into 70:15:15 for train-validate-test set\n",
    "    arg: path: input data path\n",
    "    \n",
    "    generates CSV file with slice id and corrosponding bool \n",
    "    value for train, test and validation \n",
    "    \"\"\"\n",
    "    SPLIT_TRAIN = 0.7\n",
    "    SPLIT_VALID = 0.15    \n",
    "    \n",
    "    train_files = next(os.walk(src_path))[2]\n",
    "    np.random.shuffle(train_files)\n",
    "    \n",
    "    total_samples = len(train_files)\n",
    "    print \"total number of samples: {}\".format(total_samples)\n",
    "    \n",
    "    train_ = train_files[0:int(SPLIT_TRAIN*total_samples)]\n",
    "    valid_ = train_files[int(SPLIT_TRAIN*total_samples): int((SPLIT_TRAIN+SPLIT_VALID)*total_samples)]\n",
    "    test_ = train_files[int((SPLIT_TRAIN+SPLIT_VALID)*total_samples):]\n",
    "    \n",
    "    slc, train, valid, test = [], [], [], [] # to save ids and corrosponding bool values\n",
    "    for slc_ in train_:\n",
    "        folder_path = os.path.join(src_path, slc_)\n",
    "        slc.append('.' + folder_path)\n",
    "        train.append(True)\n",
    "        valid.append(False)\n",
    "        test.append(False)\n",
    "    print \"Training Set Done!!\"\n",
    "    \n",
    "    for slc_ in valid_:\n",
    "        folder_path = os.path.join(src_path, slc_)\n",
    "        slc.append('.' + folder_path)\n",
    "        train.append(False)\n",
    "        valid.append(True)\n",
    "        test.append(False)\n",
    "    print \"Validation Set Done!!\"\n",
    "\n",
    "    for slc_ in test_:\n",
    "        folder_path = os.path.join(src_path, slc_)\n",
    "        slc.append('.' + folder_path)\n",
    "        train.append(False)\n",
    "        valid.append(False)\n",
    "        test.append(True)\n",
    "    print \"Test Set Done!!\"\n",
    "    \n",
    "    data = pd.DataFrame()\n",
    "    data['Slice Path'] = slc\n",
    "    data['Training'] = train\n",
    "    data['Testing'] = test\n",
    "    data['Validation'] = valid\n",
    "    data.to_csv(os.path.join(dest_path, 'train_test_split.csv'), index=False)\n",
    "    print \"Data Splitting Done...\"\n",
    "    \n",
    "generate_train_validate_test_set('./processed_data/hdf5_file', './processed_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Training Set Done!!\n",
      "Validation Set Done!!\n",
      "Test Set Done!!\n",
      "Data Splitting Done...\n"
     ]
    }
   ],
   "source": [
    "def generate_train_validate_test_set(src_path, dest_path):\n",
    "    \"\"\"\n",
    "    Split the data into 70:15:15 for train-validate-test set\n",
    "    arg: path: input data path\n",
    "    \"\"\"\n",
    "    SPLIT_TRAIN = 0.7\n",
    "    SPLIT_VALID = 0.15\n",
    "\n",
    "\n",
    "    dest_path = os.path.join(dest_path,'dataset')\n",
    "    if os.path.exists(dest_path):\n",
    "        shutil.rmtree(dest_path)\n",
    "    os.makedirs(os.path.join(dest_path, 'train_set'))  \n",
    "    os.makedirs(os.path.join(dest_path, 'validation_set'))  \n",
    "    os.makedirs(os.path.join(dest_path, 'test_set')) \n",
    "    \n",
    "    \n",
    "    train_folders = next(os.walk(src_path))[2]\n",
    "    np.random.shuffle(train_folders)\n",
    "    \n",
    "    total_samples = len(train_folders)\n",
    "    print total_samples\n",
    "    train_ = train_folders[0:int(SPLIT_TRAIN*total_samples)]\n",
    "    valid_ = train_folders[int(SPLIT_TRAIN*total_samples): int((SPLIT_TRAIN+SPLIT_VALID)*total_samples)]\n",
    "    test_ = train_folders[int((SPLIT_TRAIN+SPLIT_VALID)*total_samples):]\n",
    "    \n",
    "    for cell in train_:\n",
    "        folder_path = os.path.join(src_path, cell)\n",
    "        copy(folder_path, os.path.join(dest_path, 'train_set', cell))\n",
    "    print \"Training Set Done!!\"\n",
    "    \n",
    "    for cell in valid_:\n",
    "        folder_path = os.path.join(src_path, cell)\n",
    "        copy(folder_path, os.path.join(dest_path, 'validation_set', cell))\n",
    "    print \"Validation Set Done!!\"\n",
    "\n",
    "    for cell in test_:\n",
    "        folder_path = os.path.join(src_path, cell)\n",
    "        copy(folder_path, os.path.join(dest_path, 'test_set', cell))\n",
    "    print \"Test Set Done!!\"\n",
    "    print \"Data Splitting Done...\"\n",
    "    \n",
    "generate_train_validate_test_set('./processed_data/hdf5_file', './processed_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File ./loaders/train_test_split.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-c14ec53c12fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./loaders/train_test_split.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Training'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cnmc/anaconda3/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cnmc/anaconda3/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cnmc/anaconda3/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cnmc/anaconda3/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cnmc/anaconda3/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File ./loaders/train_test_split.csv does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"./loaders/train_test_split.csv\")\n",
    "data[data['Training']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cnmc/anaconda3/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from skimage.util.shape import view_as_windows\n",
    "import numpy as np\n",
    "import os, sys, shutil\n",
    "import scipy.ndimage as snd\n",
    "import h5py\n",
    "import SimpleITK as sitk\n",
    "from shutil import copy\n",
    "import nibabel as nib\n",
    "import skimage.morphology as morph\n",
    "from skimage.feature import canny\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv(\"./loaders/train_test_split.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_shape=(4,4)\n",
    "feature=[]\n",
    "target=[]\n",
    "for train_data in data[data['Training']==True]['Slice Path']:\n",
    "    with h5py.File(train_data,'r') as hdf:\n",
    "        image = np.squeeze(np.array(hdf.get('image')))\n",
    "        mask = np.squeeze(np.array(hdf.get('weight_map')))\n",
    "        B = view_as_windows(image, window_shape)\n",
    "        for b in B:\n",
    "            for b_ in b:\n",
    "                feature.append(np.ravel(b_[:,:]))\n",
    "        M = view_as_windows(mask, window_shape)\n",
    "        for m in M:\n",
    "            for m_ in m:\n",
    "                if np.sum(m_[:,:]) > 0:\n",
    "                    target.append(1)\n",
    "                else:\n",
    "                    target.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(feature, columns=list('ABCDEFGHIJKLMNOP'))\n",
    "df['target']=target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(df.iloc[:,:16],df.iloc[:,16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=1)\n",
    "clf.fit(df.iloc[:,:16],df.iloc[:,16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature=[]\n",
    "for train_data in data[data['Testing']==True]['Slice Path'][:1]:\n",
    "    with h5py.File(train_data,'r') as hdf:\n",
    "        image = np.squeeze(np.array(hdf.get('image')))\n",
    "        B = view_as_windows(image, window_shape)\n",
    "        for b in B:\n",
    "            for b_ in b:\n",
    "                test_feature.append(b_.flatten())\n",
    "df_test = pd.DataFrame(test_feature, columns=list('ABCDEFGHIJKLMNOP'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2163258390>]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c36248890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(clf.predict(df_test.iloc[:,:16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
